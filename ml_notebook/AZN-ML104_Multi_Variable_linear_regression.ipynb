{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry 4.0 의 중심, BigData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='right'><font size=2 color='gray'>Data Processing Based Python @ <font color='blue'><a href='https://www.facebook.com/jskim.kr'>FB / jskim.kr</a></font>, [김진수](bigpycraft@gmail.com)</font></div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sect4. Multi-variable linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from images import bigpycraft_copy as bpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='brown'>Ex01. Multi-variable linear regression</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictin exam score\n",
    "> regression using three inputs (x1, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAADtCAIAAABrrXViAAAAAXNSR0IArs4c6QAAAARnQU1BAACx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\nnQAAAMA0fPjw/wGddC+glq9z2QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "image/png": {
       "width": 500
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Scores for General Psychology\n",
    "bpc.Figure(bpc.ML04_IMG_01, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "> \n",
    "<br>\n",
    "$$ H(x) = Wx + b $$\n",
    "<br>\n",
    "$$ H(x1, x2, x3) = w1 x1 + w2 x2 + w3 x3 + b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "> \n",
    "<br>\n",
    "$$ H(x1, x2, x3) = w1 x1 + w2 x2 + w3 x3 + b $$\n",
    "<br>\n",
    "$$ cost(W,b) = \\frac{1}{m} \\sum^m_{i=1}(H(x1^{(i)}, x2^{(i)}, x3^{(i)} )-y^{(i)})^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_2:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b  = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "print(hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize. Need a very small learning rate for this data set\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7873b8af1084314a00bcbccc8dc8819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 62547.2890625 \n",
      "Prediction :\n",
      "[-75.96344757 -78.27629089 -83.83014679 -90.80435944 -56.97648239]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 19614.837890625 \n",
      "Prediction :\n",
      "[ 21.69748688  39.10213089  31.82624626  35.14236832  32.55316544]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 6157.78662109375 \n",
      "Prediction :\n",
      "[  76.37489319  104.81756592   96.57820129  105.65544891   82.67695618]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 1939.7125244140625 \n",
      "Prediction :\n",
      "[ 106.98739624  141.60879517  132.8306427   145.13327026  110.73886108]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 617.5654907226562 \n",
      "Prediction :\n",
      "[ 124.12684631  162.20640564  153.12724304  167.23558044  126.44911957]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 203.13729858398438 \n",
      "Prediction :\n",
      "[ 133.72323608  173.73782349  164.49076843  179.61000061  135.24415588]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 73.23114013671875 \n",
      "Prediction :\n",
      "[ 139.09654236  180.19340515  170.85298157  186.5381012   140.16760254]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 32.50749206542969 \n",
      "Prediction :\n",
      "[ 142.10548401  183.8072052   174.41511536  190.41703796  142.92350769]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 19.737699508666992 \n",
      "Prediction :\n",
      "[ 143.79071045  185.82998657  176.40963745  192.58882141  144.46583557]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 15.729873657226562 \n",
      "Prediction :\n",
      "[ 144.73486328  186.96206665  177.52651978  193.80490112  145.32879639]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 13.247166633605957 \n",
      "Prediction :\n",
      "[ 146.06376648  188.31446838  178.98654175  195.37893677  146.31259155]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 12.562139511108398 \n",
      "Prediction :\n",
      "[ 146.20278931  188.21931458  179.02929688  195.40849304  146.18890381]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 11.913301467895508 \n",
      "Prediction :\n",
      "[ 146.33810425  188.12670898  179.07095337  195.43722534  146.068573  ]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 11.2986478805542 \n",
      "Prediction :\n",
      "[ 146.4697876   188.0365448   179.11146545  195.46513367  145.95143127]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 10.716390609741211 \n",
      "Prediction :\n",
      "[ 146.59799194  187.94880676  179.15092468  195.49230957  145.83746338]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 10.164864540100098 \n",
      "Prediction :\n",
      "[ 146.72277832  187.86341858  179.18934631  195.51869202  145.7265625 ]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 9.64239501953125 \n",
      "Prediction :\n",
      "[ 146.84423828  187.7802887   179.22673035  195.5443573   145.61863708]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 9.14744758605957 \n",
      "Prediction :\n",
      "[ 146.96247864  187.69937134  179.26315308  195.56930542  145.5136261 ]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 8.678604125976562 \n",
      "Prediction :\n",
      "[ 147.07757568  187.62060547  179.29858398  195.59356689  145.41145325]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 8.234463691711426 \n",
      "Prediction :\n",
      "[ 147.18960571  187.54394531  179.33308411  195.61715698  145.31201172]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 7.813770294189453 \n",
      "Prediction :\n",
      "[ 147.29864502  187.46932983  179.3666687   195.64007568  145.21525574]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 7.4152069091796875 \n",
      "Prediction :\n",
      "[ 147.40480042  187.39668274  179.39936829  195.66235352  145.12110901]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 7.037703037261963 \n",
      "Prediction :\n",
      "[ 147.50811768  187.32600403  179.43121338  195.68400574  145.02949524]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 6.680026054382324 \n",
      "Prediction :\n",
      "[ 147.60870361  187.25717163  179.46218872  195.70504761  144.94033813]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 6.341263771057129 \n",
      "Prediction :\n",
      "[ 147.706604    187.19020081  179.49237061  195.72554016  144.85360718]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 6.020312786102295 \n",
      "Prediction :\n",
      "[ 147.8019104   187.125       179.52174377  195.74542236  144.76919556]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 5.716288089752197 \n",
      "Prediction :\n",
      "[ 147.89468384  187.06155396  179.55033875  195.76475525  144.6870575 ]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 5.4283013343811035 \n",
      "Prediction :\n",
      "[ 147.98498535  186.99977112  179.57818604  195.78353882  144.60716248]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 5.155463695526123 \n",
      "Prediction :\n",
      "[ 148.07289124  186.93965149  179.60528564  195.80180359  144.52938843]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 4.897013187408447 \n",
      "Prediction :\n",
      "[ 148.15846252  186.88111877  179.63166809  195.81954956  144.45373535]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<!--\n",
    "# ? sess.run\n",
    "'''\n",
    "Signature: sess.run(fetches, feed_dict=None, options=None, run_metadata=None)\n",
    "Docstring:\n",
    "Runs operations and evaluates tensors in `fetches`.\n",
    "\n",
    "Args:\n",
    "  fetches: A single graph element, a list of graph elements,\n",
    "    or a dictionary whose values are graph elements or lists of graph\n",
    "    elements (described above).\n",
    "  feed_dict: A dictionary that maps graph elements to values\n",
    "    (described above).\n",
    "  options: A [`RunOptions`] protocol buffer\n",
    "  run_metadata: A [`RunMetadata`] protocol buffer\n",
    "\n",
    "Returns:\n",
    "  Either a single value if `fetches` is a single graph element, or\n",
    "  a list of values if `fetches` is a list, or a dictionary with the\n",
    "  same keys as `fetches` if that is a dictionary (described above)\n",
    "  \n",
    "'''\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb077ccc40b04dcfb2d373e582dc0064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 62547.2890625 \n",
      "Prediction :\n",
      "[-75.96344757 -78.27629089 -83.83014679 -90.80435944 -56.97648239]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 19614.837890625 \n",
      "Prediction :\n",
      "[ 21.69748688  39.10213089  31.82624626  35.14236832  32.55316544]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 6157.78662109375 \n",
      "Prediction :\n",
      "[  76.37489319  104.81756592   96.57820129  105.65544891   82.67695618]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 1939.7125244140625 \n",
      "Prediction :\n",
      "[ 106.98739624  141.60879517  132.8306427   145.13327026  110.73886108]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 617.5654907226562 \n",
      "Prediction :\n",
      "[ 124.12684631  162.20640564  153.12724304  167.23558044  126.44911957]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 203.13729858398438 \n",
      "Prediction :\n",
      "[ 133.72323608  173.73782349  164.49076843  179.61000061  135.24415588]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 73.23114013671875 \n",
      "Prediction :\n",
      "[ 139.09654236  180.19340515  170.85298157  186.5381012   140.16760254]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 32.50749206542969 \n",
      "Prediction :\n",
      "[ 142.10548401  183.8072052   174.41511536  190.41703796  142.92350769]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 19.737699508666992 \n",
      "Prediction :\n",
      "[ 143.79071045  185.82998657  176.40963745  192.58882141  144.46583557]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 15.729873657226562 \n",
      "Prediction :\n",
      "[ 144.73486328  186.96206665  177.52651978  193.80490112  145.32879639]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 13.247166633605957 \n",
      "Prediction :\n",
      "[ 146.06376648  188.31446838  178.98654175  195.37893677  146.31259155]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 12.562139511108398 \n",
      "Prediction :\n",
      "[ 146.20278931  188.21931458  179.02929688  195.40849304  146.18890381]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 11.913301467895508 \n",
      "Prediction :\n",
      "[ 146.33810425  188.12670898  179.07095337  195.43722534  146.068573  ]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 11.2986478805542 \n",
      "Prediction :\n",
      "[ 146.4697876   188.0365448   179.11146545  195.46513367  145.95143127]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 10.716390609741211 \n",
      "Prediction :\n",
      "[ 146.59799194  187.94880676  179.15092468  195.49230957  145.83746338]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 10.164864540100098 \n",
      "Prediction :\n",
      "[ 146.72277832  187.86341858  179.18934631  195.51869202  145.7265625 ]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 9.64239501953125 \n",
      "Prediction :\n",
      "[ 146.84423828  187.7802887   179.22673035  195.5443573   145.61863708]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 9.14744758605957 \n",
      "Prediction :\n",
      "[ 146.96247864  187.69937134  179.26315308  195.56930542  145.5136261 ]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 8.678604125976562 \n",
      "Prediction :\n",
      "[ 147.07757568  187.62060547  179.29858398  195.59356689  145.41145325]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 8.234463691711426 \n",
      "Prediction :\n",
      "[ 147.18960571  187.54394531  179.33308411  195.61715698  145.31201172]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 7.813770294189453 \n",
      "Prediction :\n",
      "[ 147.29864502  187.46932983  179.3666687   195.64007568  145.21525574]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 7.4152069091796875 \n",
      "Prediction :\n",
      "[ 147.40480042  187.39668274  179.39936829  195.66235352  145.12110901]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 7.037703037261963 \n",
      "Prediction :\n",
      "[ 147.50811768  187.32600403  179.43121338  195.68400574  145.02949524]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 6.680026054382324 \n",
      "Prediction :\n",
      "[ 147.60870361  187.25717163  179.46218872  195.70504761  144.94033813]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 6.341263771057129 \n",
      "Prediction :\n",
      "[ 147.706604    187.19020081  179.49237061  195.72554016  144.85360718]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 6.020312786102295 \n",
      "Prediction :\n",
      "[ 147.8019104   187.125       179.52174377  195.74542236  144.76919556]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 5.716288089752197 \n",
      "Prediction :\n",
      "[ 147.89468384  187.06155396  179.55033875  195.76475525  144.6870575 ]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 5.4283013343811035 \n",
      "Prediction :\n",
      "[ 147.98498535  186.99977112  179.57818604  195.78353882  144.60716248]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 5.155463695526123 \n",
      "Prediction :\n",
      "[ 148.07289124  186.93965149  179.60528564  195.80180359  144.52938843]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 4.897013187408447 \n",
      "Prediction :\n",
      "[ 148.15846252  186.88111877  179.63166809  195.81954956  144.45373535]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <font color='brown'>Ex02. Multi-variable matmul linear regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPEAAADTCAIAAADfzWJjAAAAAXNSR0IArs4c6QAAAARnQU1BAACx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\nOls6Pf1/hCrTClnNFpQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "image/png": {
       "width": 250
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Scores for General Psychology\n",
    "bpc.Figure(bpc.ML04_IMG_02, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis using matrix\n",
    "> \n",
    "$$ w1 x1 + w2 x2 + w3 x3 + ... + wn xn $$\n",
    "<br>\n",
    "> \n",
    "$$ [x_{1}  x_{2}  x_{3}] \\times \\begin{bmatrix}     w_{1}\\\\    w_{2}\\\\    w_{3} \\end{bmatrix} = [x_1 w_1 + x_2 w_2 + x_3 w_3] $$\n",
    "<br>\n",
    "> \n",
    "$$H(X) = XW$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[73., 80., 75.], \n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.], \n",
    "          [96., 98., 100.], \n",
    "          [73., 66., 70.]]\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e546fd8cde94181b0c1f814b6ecc4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 56385.3828125 \n",
      "Prediction :\n",
      "[[-58.45818329]\n",
      " [-68.91279602]\n",
      " [-68.36896515]\n",
      " [-77.11761475]\n",
      " [-50.04731369]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 17674.51171875 \n",
      "Prediction :\n",
      "[[ 34.27562332]\n",
      " [ 42.54629135]\n",
      " [ 41.45359421]\n",
      " [ 42.47644424]\n",
      " [ 34.96785736]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 5540.70947265625 \n",
      "Prediction :\n",
      "[[  86.19387817]\n",
      " [ 104.94814301]\n",
      " [ 102.93921661]\n",
      " [ 109.4327774 ]\n",
      " [  82.5647049 ]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 1737.408203125 \n",
      "Prediction :\n",
      "[[ 115.26100922]\n",
      " [ 139.8846283 ]\n",
      " [ 137.36273193]\n",
      " [ 146.91917419]\n",
      " [ 109.21240234]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 545.2738037109375 \n",
      "Prediction :\n",
      "[[ 131.53462219]\n",
      " [ 159.44429016]\n",
      " [ 156.63522339]\n",
      " [ 167.90647888]\n",
      " [ 124.13147736]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 171.60287475585938 \n",
      "Prediction :\n",
      "[[ 140.64564514]\n",
      " [ 170.39505005]\n",
      " [ 167.4251709 ]\n",
      " [ 179.6565094 ]\n",
      " [ 132.48410034]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 54.47722625732422 \n",
      "Prediction :\n",
      "[[ 145.74656677]\n",
      " [ 176.52592468]\n",
      " [ 173.46606445]\n",
      " [ 186.23493958]\n",
      " [ 137.16036987]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 17.764307022094727 \n",
      "Prediction :\n",
      "[[ 148.60240173]\n",
      " [ 179.9584198 ]\n",
      " [ 176.84815979]\n",
      " [ 189.91798401]\n",
      " [ 139.77844238]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 6.256876468658447 \n",
      "Prediction :\n",
      "[[ 150.20126343]\n",
      " [ 181.88011169]\n",
      " [ 178.74162292]\n",
      " [ 191.97999573]\n",
      " [ 141.24417114]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 2.649864673614502 \n",
      "Prediction :\n",
      "[[ 151.09642029]\n",
      " [ 182.95599365]\n",
      " [ 179.80174255]\n",
      " [ 193.13444519]\n",
      " [ 142.06477356]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 0.9991838335990906 \n",
      "Prediction :\n",
      "[[ 152.2358551 ]\n",
      " [ 184.32362366]\n",
      " [ 181.14994812]\n",
      " [ 194.60665894]\n",
      " [ 143.10409546]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 0.9949268102645874 \n",
      "Prediction :\n",
      "[[ 152.23664856]\n",
      " [ 184.32264709]\n",
      " [ 181.14964294]\n",
      " [ 194.61076355]\n",
      " [ 143.09916687]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 0.9907022714614868 \n",
      "Prediction :\n",
      "[[ 152.23736572]\n",
      " [ 184.32173157]\n",
      " [ 181.14927673]\n",
      " [ 194.61480713]\n",
      " [ 143.09431458]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 0.9865248799324036 \n",
      "Prediction :\n",
      "[[ 152.23800659]\n",
      " [ 184.3208313 ]\n",
      " [ 181.14892578]\n",
      " [ 194.61883545]\n",
      " [ 143.08952332]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 0.9823659062385559 \n",
      "Prediction :\n",
      "[[ 152.23858643]\n",
      " [ 184.31997681]\n",
      " [ 181.14852905]\n",
      " [ 194.62284851]\n",
      " [ 143.08480835]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 0.9782459139823914 \n",
      "Prediction :\n",
      "[[ 152.23912048]\n",
      " [ 184.31919861]\n",
      " [ 181.14814758]\n",
      " [ 194.62684631]\n",
      " [ 143.08016968]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 0.974138081073761 \n",
      "Prediction :\n",
      "[[ 152.23957825]\n",
      " [ 184.31845093]\n",
      " [ 181.1477356 ]\n",
      " [ 194.63084412]\n",
      " [ 143.07559204]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 0.9700853228569031 \n",
      "Prediction :\n",
      "[[ 152.23997498]\n",
      " [ 184.31773376]\n",
      " [ 181.14730835]\n",
      " [ 194.63476562]\n",
      " [ 143.07106018]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 0.9660388827323914 \n",
      "Prediction :\n",
      "[[ 152.24034119]\n",
      " [ 184.3170929 ]\n",
      " [ 181.14686584]\n",
      " [ 194.63871765]\n",
      " [ 143.06661987]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 0.9620286226272583 \n",
      "Prediction :\n",
      "[[ 152.24061584]\n",
      " [ 184.31645203]\n",
      " [ 181.14639282]\n",
      " [ 194.6426239 ]\n",
      " [ 143.06222534]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 0.9580754041671753 \n",
      "Prediction :\n",
      "[[ 152.24085999]\n",
      " [ 184.31587219]\n",
      " [ 181.14595032]\n",
      " [ 194.64649963]\n",
      " [ 143.0579071 ]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 0.954114556312561 \n",
      "Prediction :\n",
      "[[ 152.24105835]\n",
      " [ 184.31532288]\n",
      " [ 181.14544678]\n",
      " [ 194.65037537]\n",
      " [ 143.05363464]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 0.9501966238021851 \n",
      "Prediction :\n",
      "[[ 152.24116516]\n",
      " [ 184.31481934]\n",
      " [ 181.1449585 ]\n",
      " [ 194.65420532]\n",
      " [ 143.04940796]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 0.9462801218032837 \n",
      "Prediction :\n",
      "[[ 152.24124146]\n",
      " [ 184.31434631]\n",
      " [ 181.14440918]\n",
      " [ 194.65802002]\n",
      " [ 143.04522705]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 0.942410945892334 \n",
      "Prediction :\n",
      "[[ 152.24127197]\n",
      " [ 184.31387329]\n",
      " [ 181.14387512]\n",
      " [ 194.66183472]\n",
      " [ 143.04112244]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 0.9385697245597839 \n",
      "Prediction :\n",
      "[[ 152.24125671]\n",
      " [ 184.3134613 ]\n",
      " [ 181.14332581]\n",
      " [ 194.66560364]\n",
      " [ 143.0370636 ]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 0.9347583055496216 \n",
      "Prediction :\n",
      "[[ 152.24119568]\n",
      " [ 184.31311035]\n",
      " [ 181.14279175]\n",
      " [ 194.66937256]\n",
      " [ 143.03308105]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 0.9309390783309937 \n",
      "Prediction :\n",
      "[[ 152.24108887]\n",
      " [ 184.31274414]\n",
      " [ 181.14219666]\n",
      " [ 194.67312622]\n",
      " [ 143.02909851]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 0.9271900057792664 \n",
      "Prediction :\n",
      "[[ 152.24093628]\n",
      " [ 184.31242371]\n",
      " [ 181.14161682]\n",
      " [ 194.67683411]\n",
      " [ 143.02522278]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 0.9234179258346558 \n",
      "Prediction :\n",
      "[[ 152.24075317]\n",
      " [ 184.31216431]\n",
      " [ 181.14102173]\n",
      " [ 194.68055725]\n",
      " [ 143.02134705]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <font color='brown'>Ex03. File input linear regression</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Check the train data\n",
      "--------------------------------------------------\n",
      "x_data.shape : (25, 3),   len(x_data) : 25 \n",
      "x_data : \n",
      "[[  73.   80.   75.]\n",
      " [  93.   88.   93.]\n",
      " [  89.   91.   90.]\n",
      " [  96.   98.  100.]\n",
      " [  73.   66.   70.]\n",
      " [  53.   46.   55.]\n",
      " [  69.   74.   77.]\n",
      " [  47.   56.   60.]\n",
      " [  87.   79.   90.]\n",
      " [  79.   70.   88.]\n",
      " [  69.   70.   73.]\n",
      " [  70.   65.   74.]\n",
      " [  93.   95.   91.]\n",
      " [  79.   80.   73.]\n",
      " [  70.   73.   78.]\n",
      " [  93.   89.   96.]\n",
      " [  78.   75.   68.]\n",
      " [  81.   90.   93.]\n",
      " [  88.   92.   86.]\n",
      " [  78.   83.   77.]\n",
      " [  82.   86.   90.]\n",
      " [  86.   82.   89.]\n",
      " [  78.   83.   85.]\n",
      " [  76.   83.   71.]\n",
      " [  96.   93.   95.]]\n",
      "--------------------------------------------------\n",
      "y_data.shape : (25, 1),   len(y_data) : 25 \n",
      "y_data : \n",
      "[[ 152.]\n",
      " [ 185.]\n",
      " [ 180.]\n",
      " [ 196.]\n",
      " [ 142.]\n",
      " [ 101.]\n",
      " [ 149.]\n",
      " [ 115.]\n",
      " [ 175.]\n",
      " [ 164.]\n",
      " [ 141.]\n",
      " [ 141.]\n",
      " [ 184.]\n",
      " [ 152.]\n",
      " [ 148.]\n",
      " [ 192.]\n",
      " [ 147.]\n",
      " [ 183.]\n",
      " [ 177.]\n",
      " [ 159.]\n",
      " [ 177.]\n",
      " [ 175.]\n",
      " [ 175.]\n",
      " [ 149.]\n",
      " [ 192.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "xy = np.loadtxt('./data/data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# Make sure the shape and data are OK\n",
    "print(\"# Check the train data\")\n",
    "print(\"-\"*50)\n",
    "print(\"x_data.shape : {},   len(x_data) : {} \\nx_data : \\n{}\".format(x_data.shape, len(x_data), x_data))\n",
    "print(\"-\"*50)\n",
    "print(\"y_data.shape : {},   len(y_data) : {} \\ny_data : \\n{}\".format(y_data.shape, len(y_data), y_data))\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50acf833b82940cab1caef9f5c74d7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 16731.265625 \n",
      "Prediction :\n",
      "[[ 35.97077179]\n",
      " [ 39.91320801]\n",
      " [ 41.46976471]\n",
      " [ 41.61774445]\n",
      " [ 32.22995758]\n",
      " [ 17.28501892]\n",
      " [ 26.33280945]\n",
      " [ 13.02586365]\n",
      " [ 31.87656403]\n",
      " [ 20.96903229]\n",
      " [ 28.01556396]\n",
      " [ 24.59912109]\n",
      " [ 46.59883881]\n",
      " [ 43.51340485]\n",
      " [ 25.51382446]\n",
      " [ 37.35242462]\n",
      " [ 44.71642303]\n",
      " [ 30.40687561]\n",
      " [ 45.49889374]\n",
      " [ 40.28086853]\n",
      " [ 31.91999054]\n",
      " [ 33.99428558]\n",
      " [ 31.72047424]\n",
      " [ 44.90032959]\n",
      " [ 43.72118378]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 6241.43994140625 \n",
      "Prediction :\n",
      "[[  83.51126862]\n",
      " [  97.05613708]\n",
      " [  97.77158356]\n",
      " [ 102.93663788]\n",
      " [  75.81004333]\n",
      " [  49.41826248]\n",
      " [  72.23400116]\n",
      " [  47.05670929]\n",
      " [  85.28391266]\n",
      " [  70.44182587]\n",
      " [  72.23809052]\n",
      " [  68.20581055]\n",
      " [ 104.76449585]\n",
      " [  91.86354828]\n",
      " [  71.62675476]\n",
      " [  95.34056854]\n",
      " [  90.76237488]\n",
      " [  85.49317932]\n",
      " [ 100.95064545]\n",
      " [  89.89693451]\n",
      " [  85.74625397]\n",
      " [  87.60366821]\n",
      " [  83.03871155]\n",
      " [  92.82801056]\n",
      " [ 102.94174194]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 2363.019775390625 \n",
      "Prediction :\n",
      "[[ 112.41735077]\n",
      " [ 131.8021698 ]\n",
      " [ 132.00540161]\n",
      " [ 140.22183228]\n",
      " [ 102.30885315]\n",
      " [  68.95819092]\n",
      " [ 100.14516449]\n",
      " [  67.75088501]\n",
      " [ 117.75978851]\n",
      " [ 100.5270462 ]\n",
      " [  99.12812805]\n",
      " [  94.72229004]\n",
      " [ 140.1308136 ]\n",
      " [ 121.26078796]\n",
      " [  99.66697693]\n",
      " [ 130.60115051]\n",
      " [ 118.75811768]\n",
      " [ 118.98968506]\n",
      " [ 134.66653442]\n",
      " [ 120.06456757]\n",
      " [ 118.47634125]\n",
      " [ 120.20178986]\n",
      " [ 114.2434082 ]\n",
      " [ 121.9677124 ]\n",
      " [ 138.95051575]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 929.0189819335938 \n",
      "Prediction :\n",
      "[[ 129.9927063 ]\n",
      " [ 152.92974854]\n",
      " [ 152.82072449]\n",
      " [ 162.89324951]\n",
      " [ 118.42133331]\n",
      " [  80.84072113]\n",
      " [ 117.11745453]\n",
      " [  80.33568573]\n",
      " [ 137.50823975]\n",
      " [ 118.82358551]\n",
      " [ 115.47908783]\n",
      " [ 110.84703827]\n",
      " [ 161.63397217]\n",
      " [ 139.13362122]\n",
      " [ 116.71800995]\n",
      " [ 152.04220581]\n",
      " [ 135.77836609]\n",
      " [ 139.35848999]\n",
      " [ 155.16583252]\n",
      " [ 138.40653992]\n",
      " [ 138.37886047]\n",
      " [ 140.02397156]\n",
      " [ 133.21801758]\n",
      " [ 139.68333435]\n",
      " [ 160.84529114]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 398.7878112792969 \n",
      "Prediction :\n",
      "[[ 140.67843628]\n",
      " [ 165.77656555]\n",
      " [ 165.47691345]\n",
      " [ 176.67875671]\n",
      " [ 128.21838379]\n",
      " [  88.06715393]\n",
      " [ 127.43830872]\n",
      " [  87.98954773]\n",
      " [ 149.51774597]\n",
      " [ 129.95199585]\n",
      " [ 125.42173004]\n",
      " [ 120.6530304 ]\n",
      " [ 174.70758057]\n",
      " [ 149.99905396]\n",
      " [ 127.08708191]\n",
      " [ 165.08026123]\n",
      " [ 146.12496948]\n",
      " [ 151.7449646 ]\n",
      " [ 167.6288147 ]\n",
      " [ 149.55789185]\n",
      " [ 150.48152161]\n",
      " [ 152.07771301]\n",
      " [ 144.75610352]\n",
      " [ 150.45251465]\n",
      " [ 174.15803528]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 202.70556640625 \n",
      "Prediction :\n",
      "[[ 147.17485046]\n",
      " [ 173.58824158]\n",
      " [ 173.17189026]\n",
      " [ 185.06115723]\n",
      " [ 134.17532349]\n",
      " [  92.46243286]\n",
      " [ 133.71476746]\n",
      " [  92.6451416 ]\n",
      " [ 156.82154846]\n",
      " [ 136.7217865 ]\n",
      " [ 131.46780396]\n",
      " [ 126.61693573]\n",
      " [ 182.65559387]\n",
      " [ 156.60357666]\n",
      " [ 133.3931427 ]\n",
      " [ 173.00883484]\n",
      " [ 152.41362   ]\n",
      " [ 159.27772522]\n",
      " [ 175.20521545]\n",
      " [ 156.33695984]\n",
      " [ 157.84147644]\n",
      " [ 159.40783691]\n",
      " [ 151.77235413]\n",
      " [ 156.99790955]\n",
      " [ 182.25244141]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 130.16693115234375 \n",
      "Prediction :\n",
      "[[ 151.12400818]\n",
      " [ 178.33831787]\n",
      " [ 177.85020447]\n",
      " [ 190.15820312]\n",
      " [ 137.79730225]\n",
      " [  95.13621521]\n",
      " [ 137.5320282 ]\n",
      " [  95.47762299]\n",
      " [ 161.26409912]\n",
      " [ 140.84135437]\n",
      " [ 135.14456177]\n",
      " [ 130.24462891]\n",
      " [ 187.48699951]\n",
      " [ 160.61727905]\n",
      " [ 137.22869873]\n",
      " [ 177.83059692]\n",
      " [ 156.23486328]\n",
      " [ 163.85925293]\n",
      " [ 179.8104248 ]\n",
      " [ 160.45747375]\n",
      " [ 162.31761169]\n",
      " [ 163.86575317]\n",
      " [ 156.03913879]\n",
      " [ 160.9750061 ]\n",
      " [ 187.1738739 ]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 103.30635833740234 \n",
      "Prediction :\n",
      "[[ 153.52426147]\n",
      " [ 181.22674561]\n",
      " [ 180.69422913]\n",
      " [ 193.25753784]\n",
      " [ 139.99943542]\n",
      " [  96.76325226]\n",
      " [ 139.85394287]\n",
      " [  97.20158386]\n",
      " [ 163.96678162]\n",
      " [ 143.34938049]\n",
      " [ 137.38064575]\n",
      " [ 132.45175171]\n",
      " [ 190.42329407]\n",
      " [ 163.05563354]\n",
      " [ 139.56202698]\n",
      " [ 180.76324463]\n",
      " [ 158.55574036]\n",
      " [ 166.64620972]\n",
      " [ 182.60891724]\n",
      " [ 162.96144104]\n",
      " [ 165.04023743]\n",
      " [ 166.57717896]\n",
      " [ 158.63407898]\n",
      " [ 163.39044189]\n",
      " [ 190.16589355]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 93.33399200439453 \n",
      "Prediction :\n",
      "[[ 154.98271179]\n",
      " [ 182.98324585]\n",
      " [ 182.42292786]\n",
      " [ 195.14219666]\n",
      " [ 141.33828735]\n",
      " [  97.75378418]\n",
      " [ 141.26663208]\n",
      " [  98.25147247]\n",
      " [ 165.61158752]\n",
      " [ 144.87756348]\n",
      " [ 138.7407074 ]\n",
      " [ 133.79515076]\n",
      " [ 192.20732117]\n",
      " [ 164.53607178]\n",
      " [ 140.98196411]\n",
      " [ 182.54721069]\n",
      " [ 159.96438599]\n",
      " [ 168.34197998]\n",
      " [ 184.30883789]\n",
      " [ 164.48245239]\n",
      " [ 166.69664001]\n",
      " [ 168.22671509]\n",
      " [ 160.21246338]\n",
      " [ 164.85632324]\n",
      " [ 191.98480225]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 89.6058578491211 \n",
      "Prediction :\n",
      "[[ 155.8684845 ]\n",
      " [ 184.0513916 ]\n",
      " [ 183.47341919]\n",
      " [ 196.28822327]\n",
      " [ 142.15219116]\n",
      " [  98.35732269]\n",
      " [ 142.12641907]\n",
      " [  98.89149475]\n",
      " [ 166.61309814]\n",
      " [ 145.80992126]\n",
      " [ 139.56811523]\n",
      " [ 134.61329651]\n",
      " [ 193.29066467]\n",
      " [ 165.43403625]\n",
      " [ 141.84645081]\n",
      " [ 183.63272095]\n",
      " [ 160.81828308]\n",
      " [ 169.37425232]\n",
      " [ 185.34077454]\n",
      " [ 165.40577698]\n",
      " [ 167.7046814 ]\n",
      " [ 169.23048401]\n",
      " [ 161.17271423]\n",
      " [ 165.74481201]\n",
      " [ 193.09031677]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 81.73258972167969 \n",
      "Prediction :\n",
      "[[ 157.01271057]\n",
      " [ 185.74119568]\n",
      " [ 184.96176147]\n",
      " [ 198.08602905]\n",
      " [ 143.37316895]\n",
      " [  99.56730652]\n",
      " [ 143.64703369]\n",
      " [ 100.25396729]\n",
      " [ 168.48147583]\n",
      " [ 147.95967102]\n",
      " [ 140.94522095]\n",
      " [ 136.17781067]\n",
      " [ 194.65254211]\n",
      " [ 166.33415222]\n",
      " [ 143.44062805]\n",
      " [ 185.48703003]\n",
      " [ 161.5582428 ]\n",
      " [ 171.23799133]\n",
      " [ 186.56256104]\n",
      " [ 166.49707031]\n",
      " [ 169.47001648]\n",
      " [ 170.96838379]\n",
      " [ 162.77868652]\n",
      " [ 166.48857117]\n",
      " [ 194.70877075]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 75.92243957519531 \n",
      "Prediction :\n",
      "[[ 156.76776123]\n",
      " [ 185.77438354]\n",
      " [ 184.81030273]\n",
      " [ 198.10791016]\n",
      " [ 143.32579041]\n",
      " [  99.85905457]\n",
      " [ 143.84945679]\n",
      " [ 100.6544342 ]\n",
      " [ 168.81684875]\n",
      " [ 148.71272278]\n",
      " [ 141.04600525]\n",
      " [ 136.49342346]\n",
      " [ 194.31027222]\n",
      " [ 165.804245  ]\n",
      " [ 143.71362305]\n",
      " [ 185.66860962]\n",
      " [ 160.92825317]\n",
      " [ 171.52302551]\n",
      " [ 186.15609741]\n",
      " [ 166.13186646]\n",
      " [ 169.68789673]\n",
      " [ 171.16105652]\n",
      " [ 162.90536499]\n",
      " [ 165.80847168]\n",
      " [ 194.60359192]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 70.57518768310547 \n",
      "Prediction :\n",
      "[[ 156.5349884 ]\n",
      " [ 185.804245  ]\n",
      " [ 184.66543579]\n",
      " [ 198.12944031]\n",
      " [ 143.27764893]\n",
      " [ 100.13646698]\n",
      " [ 144.04545593]\n",
      " [ 101.04197693]\n",
      " [ 169.13571167]\n",
      " [ 149.43212891]\n",
      " [ 141.14295959]\n",
      " [ 136.79443359]\n",
      " [ 193.98226929]\n",
      " [ 165.29577637]\n",
      " [ 143.97657776]\n",
      " [ 185.84129333]\n",
      " [ 160.3223114 ]\n",
      " [ 171.79971313]\n",
      " [ 185.7671814 ]\n",
      " [ 165.78297424]\n",
      " [ 169.89831543]\n",
      " [ 171.34439087]\n",
      " [ 163.02859497]\n",
      " [ 165.15802002]\n",
      " [ 194.50134277]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 65.65325927734375 \n",
      "Prediction :\n",
      "[[ 156.31390381]\n",
      " [ 185.83100891]\n",
      " [ 184.52694702]\n",
      " [ 198.15063477]\n",
      " [ 143.2288208 ]\n",
      " [ 100.40020752]\n",
      " [ 144.23518372]\n",
      " [ 101.41703796]\n",
      " [ 169.43881226]\n",
      " [ 150.11940002]\n",
      " [ 141.23623657]\n",
      " [ 137.08149719]\n",
      " [ 193.66795349]\n",
      " [ 164.8079071 ]\n",
      " [ 144.22994995]\n",
      " [ 186.00544739]\n",
      " [ 159.73947144]\n",
      " [ 172.06832886]\n",
      " [ 185.3951416 ]\n",
      " [ 165.44966125]\n",
      " [ 170.10153198]\n",
      " [ 171.51882935]\n",
      " [ 163.14848328]\n",
      " [ 164.53599548]\n",
      " [ 194.40197754]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 61.121768951416016 \n",
      "Prediction :\n",
      "[[ 156.10388184]\n",
      " [ 185.85479736]\n",
      " [ 184.39448547]\n",
      " [ 198.17146301]\n",
      " [ 143.17944336]\n",
      " [ 100.65089417]\n",
      " [ 144.41886902]\n",
      " [ 101.78004456]\n",
      " [ 169.72689819]\n",
      " [ 150.77592468]\n",
      " [ 141.32600403]\n",
      " [ 137.35520935]\n",
      " [ 193.36671448]\n",
      " [ 164.33976746]\n",
      " [ 144.47401428]\n",
      " [ 186.16149902]\n",
      " [ 159.17878723]\n",
      " [ 172.32907104]\n",
      " [ 185.03915405]\n",
      " [ 165.1312561 ]\n",
      " [ 170.29782104]\n",
      " [ 171.6847229 ]\n",
      " [ 163.26513672]\n",
      " [ 163.94107056]\n",
      " [ 194.30537415]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 56.94883346557617 \n",
      "Prediction :\n",
      "[[ 155.9044342 ]\n",
      " [ 185.87583923]\n",
      " [ 184.26782227]\n",
      " [ 198.19195557]\n",
      " [ 143.12957764]\n",
      " [ 100.88915253]\n",
      " [ 144.59677124]\n",
      " [ 102.1314621 ]\n",
      " [ 170.00064087]\n",
      " [ 151.40310669]\n",
      " [ 141.41236877]\n",
      " [ 137.61619568]\n",
      " [ 193.07803345]\n",
      " [ 163.89051819]\n",
      " [ 144.70921326]\n",
      " [ 186.30979919]\n",
      " [ 158.63937378]\n",
      " [ 172.58222961]\n",
      " [ 184.69856262]\n",
      " [ 164.8270874 ]\n",
      " [ 170.48742676]\n",
      " [ 171.8425293 ]\n",
      " [ 163.37861633]\n",
      " [ 163.37211609]\n",
      " [ 194.21147156]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 53.105377197265625 \n",
      "Prediction :\n",
      "[[ 155.71510315]\n",
      " [ 185.89424133]\n",
      " [ 184.14672852]\n",
      " [ 198.21208191]\n",
      " [ 143.07929993]\n",
      " [ 101.11554718]\n",
      " [ 144.76902771]\n",
      " [ 102.47163391]\n",
      " [ 170.26075745]\n",
      " [ 152.00219727]\n",
      " [ 141.49549866]\n",
      " [ 137.86505127]\n",
      " [ 192.80134583]\n",
      " [ 163.45939636]\n",
      " [ 144.93585205]\n",
      " [ 186.45075989]\n",
      " [ 158.1204071 ]\n",
      " [ 172.82803345]\n",
      " [ 184.37272644]\n",
      " [ 164.5365448 ]\n",
      " [ 170.67063904]\n",
      " [ 171.99258423]\n",
      " [ 163.48905945]\n",
      " [ 162.82801819]\n",
      " [ 194.12017822]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 49.56452178955078 \n",
      "Prediction :\n",
      "[[ 155.53535461]\n",
      " [ 185.91020203]\n",
      " [ 184.03091431]\n",
      " [ 198.23190308]\n",
      " [ 143.02874756]\n",
      " [ 101.33065033]\n",
      " [ 144.93588257]\n",
      " [ 102.80097961]\n",
      " [ 170.50784302]\n",
      " [ 152.57444763]\n",
      " [ 141.57550049]\n",
      " [ 138.10227966]\n",
      " [ 192.53614807]\n",
      " [ 163.04563904]\n",
      " [ 145.15426636]\n",
      " [ 186.58468628]\n",
      " [ 157.62104797]\n",
      " [ 173.06669617]\n",
      " [ 184.0609436 ]\n",
      " [ 164.25898743]\n",
      " [ 170.84762573]\n",
      " [ 172.13525391]\n",
      " [ 163.59651184]\n",
      " [ 162.30763245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 194.03143311]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 46.30180740356445 \n",
      "Prediction :\n",
      "[[ 155.36480713]\n",
      " [ 185.92385864]\n",
      " [ 183.92019653]\n",
      " [ 198.25137329]\n",
      " [ 142.97796631]\n",
      " [ 101.53495789]\n",
      " [ 145.09750366]\n",
      " [ 103.11987305]\n",
      " [ 170.74252319]\n",
      " [ 153.12106323]\n",
      " [ 141.65252686]\n",
      " [ 138.32846069]\n",
      " [ 192.28198242]\n",
      " [ 162.64852905]\n",
      " [ 145.36480713]\n",
      " [ 186.71191406]\n",
      " [ 157.14056396]\n",
      " [ 173.29849243]\n",
      " [ 183.76266479]\n",
      " [ 163.993927  ]\n",
      " [ 171.01867676]\n",
      " [ 172.27090454]\n",
      " [ 163.70111084]\n",
      " [ 161.81002808]\n",
      " [ 193.94515991]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 43.29463195800781 \n",
      "Prediction :\n",
      "[[ 155.20294189]\n",
      " [ 185.93533325]\n",
      " [ 183.81428528]\n",
      " [ 198.27049255]\n",
      " [ 142.92700195]\n",
      " [ 101.72898865]\n",
      " [ 145.25404358]\n",
      " [ 103.42865753]\n",
      " [ 170.96534729]\n",
      " [ 153.64315796]\n",
      " [ 141.72665405]\n",
      " [ 138.54402161]\n",
      " [ 192.03834534]\n",
      " [ 162.26737976]\n",
      " [ 145.56771851]\n",
      " [ 186.83273315]\n",
      " [ 156.6781311 ]\n",
      " [ 173.52355957]\n",
      " [ 183.47727966]\n",
      " [ 163.7407074 ]\n",
      " [ 171.18391418]\n",
      " [ 172.39981079]\n",
      " [ 163.8028717 ]\n",
      " [ 161.33409119]\n",
      " [ 193.86125183]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 40.52231216430664 \n",
      "Prediction :\n",
      "[[ 155.04942322]\n",
      " [ 185.94477844]\n",
      " [ 183.71302795]\n",
      " [ 198.28929138]\n",
      " [ 142.87594604]\n",
      " [ 101.9132309 ]\n",
      " [ 145.40568542]\n",
      " [ 103.72769928]\n",
      " [ 171.1769104 ]\n",
      " [ 154.14181519]\n",
      " [ 141.79800415]\n",
      " [ 138.74949646]\n",
      " [ 191.80480957]\n",
      " [ 161.90150452]\n",
      " [ 145.76333618]\n",
      " [ 186.94744873]\n",
      " [ 156.233078  ]\n",
      " [ 173.74215698]\n",
      " [ 183.20422363]\n",
      " [ 163.49884033]\n",
      " [ 171.34365845]\n",
      " [ 172.52235413]\n",
      " [ 163.90190125]\n",
      " [ 160.87893677]\n",
      " [ 193.77967834]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 37.965911865234375 \n",
      "Prediction :\n",
      "[[ 154.90380859]\n",
      " [ 185.95231628]\n",
      " [ 183.61621094]\n",
      " [ 198.30775452]\n",
      " [ 142.82484436]\n",
      " [ 102.08813477]\n",
      " [ 145.55264282]\n",
      " [ 104.01730347]\n",
      " [ 171.37774658]\n",
      " [ 154.61810303]\n",
      " [ 141.86671448]\n",
      " [ 138.94532776]\n",
      " [ 191.58093262]\n",
      " [ 161.55029297]\n",
      " [ 145.95193481]\n",
      " [ 187.05639648]\n",
      " [ 155.80471802]\n",
      " [ 173.95448303]\n",
      " [ 182.94299316]\n",
      " [ 163.26786804]\n",
      " [ 171.49804688]\n",
      " [ 172.63877869]\n",
      " [ 163.99829102]\n",
      " [ 160.44367981]\n",
      " [ 193.7003479 ]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 35.60803985595703 \n",
      "Prediction :\n",
      "[[ 154.76573181]\n",
      " [ 185.95806885]\n",
      " [ 183.52363586]\n",
      " [ 198.3258667 ]\n",
      " [ 142.77377319]\n",
      " [ 102.25414276]\n",
      " [ 145.69499207]\n",
      " [ 104.29782104]\n",
      " [ 171.5683136 ]\n",
      " [ 155.07296753]\n",
      " [ 141.93287659]\n",
      " [ 139.13195801]\n",
      " [ 191.36633301]\n",
      " [ 161.21313477]\n",
      " [ 146.1337738 ]\n",
      " [ 187.1598053 ]\n",
      " [ 155.39237976]\n",
      " [ 174.16070557]\n",
      " [ 182.69300842]\n",
      " [ 163.04722595]\n",
      " [ 171.64729309]\n",
      " [ 172.74937439]\n",
      " [ 164.09207153]\n",
      " [ 160.02740479]\n",
      " [ 193.62319946]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 33.43275451660156 \n",
      "Prediction :\n",
      "[[ 154.63487244]\n",
      " [ 185.9621582 ]\n",
      " [ 183.43510437]\n",
      " [ 198.34367371]\n",
      " [ 142.72276306]\n",
      " [ 102.41168213]\n",
      " [ 145.83294678]\n",
      " [ 104.56954193]\n",
      " [ 171.74914551]\n",
      " [ 155.50740051]\n",
      " [ 141.99658203]\n",
      " [ 139.30978394]\n",
      " [ 191.16059875]\n",
      " [ 160.88946533]\n",
      " [ 146.30912781]\n",
      " [ 187.25794983]\n",
      " [ 154.99545288]\n",
      " [ 174.36103821]\n",
      " [ 182.45387268]\n",
      " [ 162.83653259]\n",
      " [ 171.79156494]\n",
      " [ 172.85444641]\n",
      " [ 164.18336487]\n",
      " [ 159.62931824]\n",
      " [ 193.54818726]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 31.425342559814453 \n",
      "Prediction :\n",
      "[[ 154.51083374]\n",
      " [ 185.96466064]\n",
      " [ 183.35046387]\n",
      " [ 198.36112976]\n",
      " [ 142.671875  ]\n",
      " [ 102.56113434]\n",
      " [ 145.96662903]\n",
      " [ 104.8327713 ]\n",
      " [ 171.92066956]\n",
      " [ 155.92227173]\n",
      " [ 142.05792236]\n",
      " [ 139.47923279]\n",
      " [ 190.96336365]\n",
      " [ 160.57868958]\n",
      " [ 146.47819519]\n",
      " [ 187.35105896]\n",
      " [ 154.61329651]\n",
      " [ 174.5556488 ]\n",
      " [ 182.22505188]\n",
      " [ 162.6353302 ]\n",
      " [ 171.93106079]\n",
      " [ 172.95422363]\n",
      " [ 164.27224731]\n",
      " [ 159.24862671]\n",
      " [ 193.47525024]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 29.57241439819336 \n",
      "Prediction :\n",
      "[[ 154.39335632]\n",
      " [ 185.96569824]\n",
      " [ 183.26951599]\n",
      " [ 198.37826538]\n",
      " [ 142.62117004]\n",
      " [ 102.70291138]\n",
      " [ 146.09620667]\n",
      " [ 105.0878067 ]\n",
      " [ 172.08332825]\n",
      " [ 156.31846619]\n",
      " [ 142.11701965]\n",
      " [ 139.64067078]\n",
      " [ 190.77429199]\n",
      " [ 160.28030396]\n",
      " [ 146.64128113]\n",
      " [ 187.43940735]\n",
      " [ 154.24534607]\n",
      " [ 174.74468994]\n",
      " [ 182.00613403]\n",
      " [ 162.44316101]\n",
      " [ 172.06593323]\n",
      " [ 173.04896545]\n",
      " [ 164.35873413]\n",
      " [ 158.884552  ]\n",
      " [ 193.40428162]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 27.86157989501953 \n",
      "Prediction :\n",
      "[[ 154.2820282 ]\n",
      " [ 185.96537781]\n",
      " [ 183.19212341]\n",
      " [ 198.39511108]\n",
      " [ 142.57066345]\n",
      " [ 102.83733368]\n",
      " [ 146.22177124]\n",
      " [ 105.33490753]\n",
      " [ 172.23754883]\n",
      " [ 156.6967926 ]\n",
      " [ 142.17391968]\n",
      " [ 139.79444885]\n",
      " [ 190.59295654]\n",
      " [ 159.99378967]\n",
      " [ 146.79856873]\n",
      " [ 187.52314758]\n",
      " [ 153.89103699]\n",
      " [ 174.92835999]\n",
      " [ 181.79663086]\n",
      " [ 162.25967407]\n",
      " [ 172.19633484]\n",
      " [ 173.13890076]\n",
      " [ 164.44291687]\n",
      " [ 158.53636169]\n",
      " [ 193.33525085]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 26.281532287597656 \n",
      "Prediction :\n",
      "[[ 154.176651  ]\n",
      " [ 185.96376038]\n",
      " [ 183.11810303]\n",
      " [ 198.41160583]\n",
      " [ 142.520401  ]\n",
      " [ 102.96477509]\n",
      " [ 146.34350586]\n",
      " [ 105.57434082]\n",
      " [ 172.38372803]\n",
      " [ 157.05805969]\n",
      " [ 142.22874451]\n",
      " [ 139.94094849]\n",
      " [ 190.41912842]\n",
      " [ 159.71865845]\n",
      " [ 146.95027161]\n",
      " [ 187.60256958]\n",
      " [ 153.54981995]\n",
      " [ 175.10682678]\n",
      " [ 181.59619141]\n",
      " [ 162.08444214]\n",
      " [ 172.32246399]\n",
      " [ 173.22424316]\n",
      " [ 164.52487183]\n",
      " [ 158.20341492]\n",
      " [ 193.26812744]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 24.82184410095215 \n",
      "Prediction :\n",
      "[[ 154.0769043 ]\n",
      " [ 185.96096802]\n",
      " [ 183.04736328]\n",
      " [ 198.42779541]\n",
      " [ 142.47045898]\n",
      " [ 103.08557129]\n",
      " [ 146.46151733]\n",
      " [ 105.80638123]\n",
      " [ 172.52227783]\n",
      " [ 157.4030304 ]\n",
      " [ 142.28153992]\n",
      " [ 140.08045959]\n",
      " [ 190.25245667]\n",
      " [ 159.454422  ]\n",
      " [ 147.09663391]\n",
      " [ 187.67784119]\n",
      " [ 153.22122192]\n",
      " [ 175.28024292]\n",
      " [ 181.40441895]\n",
      " [ 161.91711426]\n",
      " [ 172.44445801]\n",
      " [ 173.30525208]\n",
      " [ 164.60464478]\n",
      " [ 157.88499451]\n",
      " [ 193.20283508]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 23.472959518432617 \n",
      "Prediction :\n",
      "[[ 153.98248291]\n",
      " [ 185.95709229]\n",
      " [ 182.97970581]\n",
      " [ 198.44367981]\n",
      " [ 142.42082214]\n",
      " [ 103.20001984]\n",
      " [ 146.57592773]\n",
      " [ 106.03125763]\n",
      " [ 172.65350342]\n",
      " [ 157.73242188]\n",
      " [ 142.33242798]\n",
      " [ 140.21333313]\n",
      " [ 190.09262085]\n",
      " [ 159.20066833]\n",
      " [ 147.237854  ]\n",
      " [ 187.74919128]\n",
      " [ 152.90472412]\n",
      " [ 175.44876099]\n",
      " [ 181.22091675]\n",
      " [ 161.75733948]\n",
      " [ 172.56243896]\n",
      " [ 173.38208008]\n",
      " [ 164.68229675]\n",
      " [ 157.58047485]\n",
      " [ 193.13929749]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9886cb29246d4ec4b8554b8c609d5c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0 \tCost : 16731.265625 \n",
      "Step : 1 \tCost : 6241.43994140625 \n",
      "Step : 2 \tCost : 2363.019775390625 \n",
      "Step : 3 \tCost : 929.0189819335938 \n",
      "Step : 4 \tCost : 398.7878112792969 \n",
      "Step : 5 \tCost : 202.70556640625 \n",
      "Step : 6 \tCost : 130.16693115234375 \n",
      "Step : 7 \tCost : 103.30635833740234 \n",
      "Step : 8 \tCost : 93.33399200439453 \n",
      "Step : 9 \tCost : 89.6058578491211 \n",
      "Step : 100 \tCost : 81.73258972167969 \n",
      "Step : 200 \tCost : 75.92243957519531 \n",
      "Step : 300 \tCost : 70.57518768310547 \n",
      "Step : 400 \tCost : 65.65325927734375 \n",
      "Step : 500 \tCost : 61.121768951416016 \n",
      "Step : 600 \tCost : 56.94883346557617 \n",
      "Step : 700 \tCost : 53.105377197265625 \n",
      "Step : 800 \tCost : 49.56452178955078 \n",
      "Step : 900 \tCost : 46.30180740356445 \n",
      "Step : 1000 \tCost : 43.29463195800781 \n",
      "Step : 1100 \tCost : 40.52231216430664 \n",
      "Step : 1200 \tCost : 37.965911865234375 \n",
      "Step : 1300 \tCost : 35.60803985595703 \n",
      "Step : 1400 \tCost : 33.43275451660156 \n",
      "Step : 1500 \tCost : 31.425342559814453 \n",
      "Step : 1600 \tCost : 29.57241439819336 \n",
      "Step : 1700 \tCost : 27.86157989501953 \n",
      "Step : 1800 \tCost : 26.281532287597656 \n",
      "Step : 1900 \tCost : 24.82184410095215 \n",
      "Step : 2000 \tCost : 23.472959518432617 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        # print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "        print(\"Step : {} \\tCost : {} \".format(step, cost_val))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ask your score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score \t: \n",
      " [[ 183.3119812]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Your score \\t: \\n\", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other scores \t: \n",
      " [[ 146.94897461]\n",
      " [ 186.56742859]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOther scores \\t: \\n\", sess.run(hypothesis,\n",
    "                                        feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='brown'>Ex04. TF reader linear regression 5</font>\n",
    "> \n",
    "- 참조 : https://www.tensorflow.org/programmers_guide/reading_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis using matrix\n",
    "> \n",
    "$$ w1 x1 + w2 x2 + w3 x3 + ... + wn xn $$\n",
    "<br>\n",
    "> \n",
    "$$\n",
    "[x_{1}  x_{2}  x_{3}] \\times\n",
    "\\begin{bmatrix}\n",
    "    w_{1}\\\\\n",
    "    w_{2}\\\\\n",
    "    w_{3}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "[x_1 w_1 + x_2 w_2 + x_3 w_3]\n",
    "$$\n",
    "<br>\n",
    "> \n",
    "$$H(X) = XW$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "``` python\n",
    "# decoded result.\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "# collect batches of csv in\n",
    "train_x_batch, train_y_batch = \\\n",
    "    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "    \n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    ['./data/data-01-test-score.csv'], shuffle=False, name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Default values, in case of empty columns. Also specifies the type of the\n",
    "# decoded result.\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "# collect batches of csv in\n",
    "train_x_batch, train_y_batch = \\\n",
    "    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799debba063340739ff72bbe7ea4cbf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 12282.818359375 \n",
      "Prediction :\n",
      "[[ 43.87703323]\n",
      " [ 56.75808716]\n",
      " [ 53.8187561 ]\n",
      " [ 58.70309448]\n",
      " [ 44.26979065]\n",
      " [ 33.36067963]\n",
      " [ 43.03390503]\n",
      " [ 30.48879433]\n",
      " [ 54.14667892]\n",
      " [ 50.78905487]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 5281.35009765625 \n",
      "Prediction :\n",
      "[[  79.32762146]\n",
      " [  80.08456421]\n",
      " [ 103.87862396]\n",
      " [  86.50222015]\n",
      " [  82.18635559]\n",
      " [ 105.53392792]\n",
      " [  83.52199554]\n",
      " [  96.50223541]\n",
      " [  98.39302826]\n",
      " [  87.64356995]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 2229.998779296875 \n",
      "Prediction :\n",
      "[[ 126.1040802 ]\n",
      " [ 127.95698547]\n",
      " [ 119.86204529]\n",
      " [ 111.0045929 ]\n",
      " [ 140.79554749]\n",
      " [ 110.23571777]\n",
      " [ 136.5345459 ]\n",
      " [ 132.4133606 ]\n",
      " [ 144.3036499 ]\n",
      " [ 105.11299896]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 479.7852478027344 \n",
      "Prediction :\n",
      "[[  90.61560059]\n",
      " [ 124.8108139 ]\n",
      " [  91.11456299]\n",
      " [ 149.30528259]\n",
      " [ 138.93873596]\n",
      " [ 121.35749817]\n",
      " [ 121.51516724]\n",
      " [ 159.18089294]\n",
      " [ 132.48200989]\n",
      " [ 126.00740814]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 398.9161682128906 \n",
      "Prediction :\n",
      "[[ 169.52233887]\n",
      " [ 134.35600281]\n",
      " [ 157.29376221]\n",
      " [ 159.60540771]\n",
      " [ 142.41500854]\n",
      " [ 155.10369873]\n",
      " [ 156.83964539]\n",
      " [ 147.51036072]\n",
      " [ 136.82537842]\n",
      " [ 172.70095825]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 78.41851806640625 \n",
      "Prediction :\n",
      "[[ 143.41525269]\n",
      " [ 176.41021729]\n",
      " [ 171.70504761]\n",
      " [ 187.0960083 ]\n",
      " [ 135.52331543]\n",
      " [ 100.64907837]\n",
      " [ 139.14456177]\n",
      " [ 101.74459839]\n",
      " [ 165.98101807]\n",
      " [ 154.38919067]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 39.1659049987793 \n",
      "Prediction :\n",
      "[[ 137.92236328]\n",
      " [ 137.85081482]\n",
      " [ 180.96282959]\n",
      " [ 150.58508301]\n",
      " [ 143.28285217]\n",
      " [ 182.36122131]\n",
      " [ 144.55064392]\n",
      " [ 169.49452209]\n",
      " [ 171.88516235]\n",
      " [ 153.40293884]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 32.263797760009766 \n",
      "Prediction :\n",
      "[[ 169.26275635]\n",
      " [ 170.93804932]\n",
      " [ 161.01017761]\n",
      " [ 149.43408203]\n",
      " [ 188.27555847]\n",
      " [ 148.35536194]\n",
      " [ 182.34803772]\n",
      " [ 177.55545044]\n",
      " [ 193.46853638]\n",
      " [ 140.05111694]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 12.083057403564453 \n",
      "Prediction :\n",
      "[[ 105.09909821]\n",
      " [ 145.50285339]\n",
      " [ 106.46078491]\n",
      " [ 173.37712097]\n",
      " [ 161.24235535]\n",
      " [ 141.29011536]\n",
      " [ 141.17076111]\n",
      " [ 185.39219666]\n",
      " [ 154.26669312]\n",
      " [ 146.79502869]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 29.256296157836914 \n",
      "Prediction :\n",
      "[[ 187.12060547]\n",
      " [ 148.32728577]\n",
      " [ 174.01956177]\n",
      " [ 176.43652344]\n",
      " [ 157.47569275]\n",
      " [ 171.44378662]\n",
      " [ 173.10894775]\n",
      " [ 163.0894928 ]\n",
      " [ 151.37367249]\n",
      " [ 190.67282104]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 9.854233741760254 \n",
      "Prediction :\n",
      "[[ 152.33514404]\n",
      " [ 187.07801819]\n",
      " [ 182.24064636]\n",
      " [ 198.60557556]\n",
      " [ 143.616745  ]\n",
      " [ 106.66459656]\n",
      " [ 147.82759094]\n",
      " [ 108.27786255]\n",
      " [ 175.98191833]\n",
      " [ 163.72618103]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 9.5703706741333 \n",
      "Prediction :\n",
      "[[ 152.34745789]\n",
      " [ 187.03529358]\n",
      " [ 182.2252655 ]\n",
      " [ 198.62457275]\n",
      " [ 143.5403595 ]\n",
      " [ 106.65668488]\n",
      " [ 147.91110229]\n",
      " [ 108.43837738]\n",
      " [ 175.9723053 ]\n",
      " [ 163.7911377 ]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 9.301576614379883 \n",
      "Prediction :\n",
      "[[ 152.36016846]\n",
      " [ 186.99324036]\n",
      " [ 182.21054077]\n",
      " [ 198.64303589]\n",
      " [ 143.46554565]\n",
      " [ 106.64806366]\n",
      " [ 147.99232483]\n",
      " [ 108.59452057]\n",
      " [ 175.96185303]\n",
      " [ 163.8526001 ]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 9.04703426361084 \n",
      "Prediction :\n",
      "[[ 152.37321472]\n",
      " [ 186.95188904]\n",
      " [ 182.19645691]\n",
      " [ 198.66099548]\n",
      " [ 143.39231873]\n",
      " [ 106.63877869]\n",
      " [ 148.07131958]\n",
      " [ 108.74641418]\n",
      " [ 175.95065308]\n",
      " [ 163.91075134]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 8.805887222290039 \n",
      "Prediction :\n",
      "[[ 152.3865509 ]\n",
      " [ 186.91117859]\n",
      " [ 182.18296814]\n",
      " [ 198.67845154]\n",
      " [ 143.32060242]\n",
      " [ 106.62889862]\n",
      " [ 148.14814758]\n",
      " [ 108.89419556]\n",
      " [ 175.93873596]\n",
      " [ 163.9657135 ]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 8.577499389648438 \n",
      "Prediction :\n",
      "[[ 152.40019226]\n",
      " [ 186.8711853 ]\n",
      " [ 182.17007446]\n",
      " [ 198.69548035]\n",
      " [ 143.2504425 ]\n",
      " [ 106.61846924]\n",
      " [ 148.22288513]\n",
      " [ 109.0379715 ]\n",
      " [ 175.9262085 ]\n",
      " [ 164.01773071]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 8.361085891723633 \n",
      "Prediction :\n",
      "[[ 152.4140625 ]\n",
      " [ 186.83184814]\n",
      " [ 182.1577301 ]\n",
      " [ 198.71202087]\n",
      " [ 143.1817627 ]\n",
      " [ 106.60754395]\n",
      " [ 148.29559326]\n",
      " [ 109.17785645]\n",
      " [ 175.9131012 ]\n",
      " [ 164.06686401]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 8.155996322631836 \n",
      "Prediction :\n",
      "[[ 152.42816162]\n",
      " [ 186.79319763]\n",
      " [ 182.14590454]\n",
      " [ 198.7281189 ]\n",
      " [ 143.11453247]\n",
      " [ 106.59615326]\n",
      " [ 148.36633301]\n",
      " [ 109.31396484]\n",
      " [ 175.8994751 ]\n",
      " [ 164.11328125]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 7.961634635925293 \n",
      "Prediction :\n",
      "[[ 152.44241333]\n",
      " [ 186.75518799]\n",
      " [ 182.13461304]\n",
      " [ 198.74377441]\n",
      " [ 143.04875183]\n",
      " [ 106.58435822]\n",
      " [ 148.43511963]\n",
      " [ 109.44639587]\n",
      " [ 175.88534546]\n",
      " [ 164.15710449]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 7.777369022369385 \n",
      "Prediction :\n",
      "[[ 152.45680237]\n",
      " [ 186.71784973]\n",
      " [ 182.12376404]\n",
      " [ 198.75900269]\n",
      " [ 142.98435974]\n",
      " [ 106.5721817 ]\n",
      " [ 148.50202942]\n",
      " [ 109.57526398]\n",
      " [ 175.87077332]\n",
      " [ 164.19847107]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 7.60275936126709 \n",
      "Prediction :\n",
      "[[ 152.47135925]\n",
      " [ 186.68119812]\n",
      " [ 182.11341858]\n",
      " [ 198.77384949]\n",
      " [ 142.92137146]\n",
      " [ 106.55969238]\n",
      " [ 148.56716919]\n",
      " [ 109.70067596]\n",
      " [ 175.85586548]\n",
      " [ 164.23753357]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 7.437191009521484 \n",
      "Prediction :\n",
      "[[ 152.48599243]\n",
      " [ 186.64520264]\n",
      " [ 182.10350037]\n",
      " [ 198.78826904]\n",
      " [ 142.85975647]\n",
      " [ 106.54689789]\n",
      " [ 148.63052368]\n",
      " [ 109.82272339]\n",
      " [ 175.84060669]\n",
      " [ 164.27438354]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 7.280221462249756 \n",
      "Prediction :\n",
      "[[ 152.50068665]\n",
      " [ 186.60983276]\n",
      " [ 182.0940094 ]\n",
      " [ 198.80230713]\n",
      " [ 142.79945374]\n",
      " [ 106.53384399]\n",
      " [ 148.69218445]\n",
      " [ 109.94148254]\n",
      " [ 175.82505798]\n",
      " [ 164.30909729]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 7.131389617919922 \n",
      "Prediction :\n",
      "[[ 152.51547241]\n",
      " [ 186.57514954]\n",
      " [ 182.0848999 ]\n",
      " [ 198.815979  ]\n",
      " [ 142.74047852]\n",
      " [ 106.52056885]\n",
      " [ 148.75216675]\n",
      " [ 110.05708313]\n",
      " [ 175.80923462]\n",
      " [ 164.34182739]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 6.9902801513671875 \n",
      "Prediction :\n",
      "[[ 152.53027344]\n",
      " [ 186.54109192]\n",
      " [ 182.07621765]\n",
      " [ 198.82928467]\n",
      " [ 142.68280029]\n",
      " [ 106.50708771]\n",
      " [ 148.81054688]\n",
      " [ 110.16957855]\n",
      " [ 175.79318237]\n",
      " [ 164.37266541]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 6.856436729431152 \n",
      "Prediction :\n",
      "[[ 152.54508972]\n",
      " [ 186.50764465]\n",
      " [ 182.06788635]\n",
      " [ 198.84222412]\n",
      " [ 142.62635803]\n",
      " [ 106.49344635]\n",
      " [ 148.86732483]\n",
      " [ 110.27909088]\n",
      " [ 175.77693176]\n",
      " [ 164.40170288]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 6.729528903961182 \n",
      "Prediction :\n",
      "[[ 152.55992126]\n",
      " [ 186.47485352]\n",
      " [ 182.05992126]\n",
      " [ 198.85482788]\n",
      " [ 142.57118225]\n",
      " [ 106.47963715]\n",
      " [ 148.92262268]\n",
      " [ 110.38565826]\n",
      " [ 175.76052856]\n",
      " [ 164.42901611]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 6.6091790199279785 \n",
      "Prediction :\n",
      "[[ 152.57472229]\n",
      " [ 186.44265747]\n",
      " [ 182.05229187]\n",
      " [ 198.86711121]\n",
      " [ 142.51721191]\n",
      " [ 106.46573639]\n",
      " [ 148.97644043]\n",
      " [ 110.48941803]\n",
      " [ 175.7440033 ]\n",
      " [ 164.45471191]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 6.495053291320801 \n",
      "Prediction :\n",
      "[[ 152.5894928 ]\n",
      " [ 186.41110229]\n",
      " [ 182.04498291]\n",
      " [ 198.87905884]\n",
      " [ 142.46443176]\n",
      " [ 106.45173645]\n",
      " [ 149.02877808]\n",
      " [ 110.5904007 ]\n",
      " [ 175.72735596]\n",
      " [ 164.47886658]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 6.386807918548584 \n",
      "Prediction :\n",
      "[[ 152.60421753]\n",
      " [ 186.38015747]\n",
      " [ 182.03799438]\n",
      " [ 198.89068604]\n",
      " [ 142.41281128]\n",
      " [ 106.43765259]\n",
      " [ 149.07974243]\n",
      " [ 110.68870544]\n",
      " [ 175.71064758]\n",
      " [ 164.5015564 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Start populating the filename queue.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_batch, Y: y_batch})\n",
    "    \n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score \t: \n",
      " [[ 190.80329895]]\n",
      "\n",
      "Other scores \t: \n",
      " [[ 170.19667053]\n",
      " [ 177.01216125]]\n"
     ]
    }
   ],
   "source": [
    "# Ask my score\n",
    "print(\"Your score \\t: \\n\", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))\n",
    "\n",
    "print(\"\\nOther scores \\t: \\n\", sess.run(hypothesis,\n",
    "                                        feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 69.,  70.,  73.],\n",
       "        [ 70.,  65.,  74.],\n",
       "        [ 93.,  95.,  91.],\n",
       "        [ 79.,  80.,  73.],\n",
       "        [ 70.,  73.,  78.],\n",
       "        [ 93.,  89.,  96.],\n",
       "        [ 78.,  75.,  68.],\n",
       "        [ 81.,  90.,  93.],\n",
       "        [ 88.,  92.,  86.],\n",
       "        [ 78.,  83.,  77.]], dtype=float32), array([[ 141.],\n",
       "        [ 141.],\n",
       "        [ 184.],\n",
       "        [ 152.],\n",
       "        [ 148.],\n",
       "        [ 192.],\n",
       "        [ 147.],\n",
       "        [ 183.],\n",
       "        [ 177.],\n",
       "        [ 159.]], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([train_x_batch, train_y_batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<marquee><font size=3 color='brown'>The BigpyCraft find the information to design valuable society with Technology & Craft.</font></marquee>\n",
    "<div align='right'><font size=2 color='gray'> &lt; The End &gt; </font></div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
